{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "160756ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# script to download data periodically for the past hour and process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1539ffa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import os\n",
    "import connection\n",
    "import configs\n",
    "from datetime import datetime, timedelta\n",
    "import pytz\n",
    "import re\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7c50e144",
   "metadata": {},
   "outputs": [],
   "source": [
    "# search query (can be changed easily)\n",
    "\n",
    "search_query = 'covid -is:retweet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e9c4c4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make call to Twitter API for results\n",
    "\n",
    "previous_hour = (datetime.now() - timedelta(hours = 1)).astimezone(pytz.utc)\n",
    "\n",
    "paginator_tweets = tweepy.Paginator(\n",
    "    connection.tweepy_client.search_recent_tweets,\n",
    "    query=search_query,\n",
    "    tweet_fields=['created_at', 'lang', 'author_id', 'entities'], \n",
    "    start_time=previous_hour,\n",
    "    max_results=100,\n",
    ").flatten(limit=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2610c854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process tweets.txt file\n",
    "\n",
    "df = pd.DataFrame(paginator_tweets)\n",
    "df = df.replace(r'\\n','\\t', regex=True)\n",
    "df['json'] = df.apply(lambda x: x.to_json(), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a09557b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make directory for current hour processing and save processed files there\n",
    "\n",
    "dir = os.path.join(str(previous_hour))\n",
    "os.makedirs(dir)\n",
    "np.savetxt(f'{dir}/tweets_with_more_params.txt', df['json'], fmt='%s', delimiter='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5aad930e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process tweets_text.txt file\n",
    "\n",
    "tweets_read = pd.read_json(f'{dir}/tweets_with_more_params.txt', lines=True)\n",
    "df = pd.DataFrame(tweets_read)\n",
    "df = df.replace(r'\\t','\\n', regex=True)\n",
    "np.savetxt(f'{dir}/tweets_text_with_more_params.txt', df.text, fmt='%s', delimiter='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3138433b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process Hashtags\n",
    "\n",
    "hashtags = []\n",
    "i=0\n",
    "file_reader = open(f'{dir}/tweets_text_with_more_params.txt','r')\n",
    "for line in file_reader:\n",
    "    hashtags += re.findall(r'#(\\w+)', line)\n",
    "counter_dict = dict(Counter(hashtags))\n",
    "sorted_hashtags = dict(sorted(counter_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "file_name=f'{dir}/hashtags_with_more_params.txt'\n",
    "with open(file_name, 'a+') as file_writer:\n",
    "    for item in sorted_hashtags:\n",
    "        file_writer.write(\"%s %s\\n\" % (item, sorted_hashtags[item]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4ff634",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process Mentions\n",
    "\n",
    "import re\n",
    "from collections import Counter\n",
    "mentions = []\n",
    "i=0\n",
    "file_reader = open(f'{dir}/tweets_text_with_more_params.txt','r')\n",
    "for line in file_reader:\n",
    "    mentions += re.findall(\"@([a-zA-Z0-9_]{1,50})\", line)\n",
    "counter_dict = dict(Counter(mentions))\n",
    "sorted_mentions = dict(sorted(counter_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "\n",
    "file_name=f'{dir}/mentions_with_more_params.txt'\n",
    "with open(file_name, 'a+') as file_writer:\n",
    "    for item in sorted_mentions:\n",
    "        file_writer.write(\"%s %s\\n\" % (item, sorted_mentions[item]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
